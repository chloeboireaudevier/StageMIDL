{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da783289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec7d4b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd # type: ignore\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np #type: ignore\n",
    "from tqdm import tqdm #type: ignore\n",
    "import json\n",
    "import demjson3 # type: ignore\n",
    "from IPython.display import clear_output # type: ignore\n",
    "from dotenv import load_dotenv #type: ignore\n",
    "from mistralai import Mistral #type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b0cfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"keys.txt\")\n",
    "key = f.readline().strip('\\n')\n",
    "f.close()\n",
    "key = key[12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a1d0a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = key\n",
    "model = \"open-mistral-nemo\"\n",
    "\n",
    "client = Mistral(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdc2086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reprise de la même architecture que celle utilisée par Luciano\n",
    "\n",
    "PROMPT_FOLDER_OPENAI = 'prompts_openai'\n",
    "PROMPT_FOLDER_MISTRAL = 'prompts_mistral'\n",
    "PROMPT_FOLDER_MISTRAL_VOUVOIEMENT = 'prompts_mistral_vouvoiement'\n",
    "PROMPT_FOLDER_MISTRAL_FORMV2 = 'prompts_mistral_form_v2'\n",
    "OUT_FILE = 'dialogue_acts_example' + '.csv'\n",
    "OUT_FOLDER = 'labeled_conversations'\n",
    "LABEL_COLUMN_1 = 'forme'\n",
    "LABEL_COLUMN_2 = 'ton'\n",
    "LABEL_COLUMN_3 = 'content'\n",
    "LABEL_COLUMN_4 = 'nature'\n",
    "LABEL_COLUMN_5 = 'formv2'\n",
    "#ajouter ici les autres labels des attributs\n",
    "CATEGORY_COLUMN = 'type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb5824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dataframe(list_of_json: list, \n",
    "                        label_columns: list):\n",
    "\n",
    "    '''\n",
    "    Converts a list of JSON strings into a flattened Pandas DataFrame.\n",
    "\n",
    "    This function processes a list of JSON strings, each representing a conversation with\n",
    "    messages and annotations. It flattens the nested structure of the JSON and constructs\n",
    "    a DataFrame with columns for activity ID, user ID, message metadata, and annotations.\n",
    "\n",
    "    Args:\n",
    "        list_of_json (list): A list of JSON strings, where each string represents a conversation.\n",
    "        label_column (str): The name of the column to store annotations (e.g., labels).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the flattened conversation data with columns:\n",
    "            - activity_id: The ID of the activity.\n",
    "            - user_id: The ID of the user.\n",
    "            - role: The role of the speaker (e.g., user, model).\n",
    "            - message_num: The message number in the conversation.\n",
    "            - utterance_num: The utterance number within the same message and role.\n",
    "            - sentence_en: The English sentence of the message.\n",
    "            - <label_column>: The annotation or label for the message.\n",
    "\n",
    "    Raises:\n",
    "        JSONDecodeError: If a JSON string cannot be decoded using `json.loads`.\n",
    "        demjson3.JSONDecodeError: If a JSON string cannot be decoded using `demjson3.decode`.\n",
    "    '''\n",
    "    # A list to save every entry (row for our dataframe)\n",
    "    flattened_data = []\n",
    "\n",
    "    for entry in list_of_json:\n",
    "        # First try to decode the string using vanilla JSON module\n",
    "        try: \n",
    "            # Try to do the conversion \n",
    "            json_entry = json.loads(entry)\n",
    "\n",
    "        # In case of error use demjson3 which is capable to deal\n",
    "        # with JSON-like string (that use single quotes instead of double quotes)\n",
    "        except:\n",
    "            # Print the entry that trigger the exception for manual inspection \n",
    "            print(entry)\n",
    "            json_entry = demjson3.decode(entry)\n",
    "\n",
    "        # Get the IDs of the activity and the conversation\n",
    "        seance_id = json_entry['seance_ID']\n",
    "        groupe_id = json_entry['groupe_ID']\n",
    "        # For every utterance in the conversation\n",
    "        for message in json_entry['conversation']:\n",
    "            # Create an entry (row) to use then in the dataframe\n",
    "            flattened_data.append({\n",
    "                'seance_ID' : seance_id,\n",
    "                'groupe_ID': groupe_id,\n",
    "                'messageID': message['messageID'],\n",
    "                'role': message['role'],\n",
    "                'message': message['message'],\n",
    "                label_columns[0] : message['annotation']['form'],    #ajouter ici les autres attributs\n",
    "                label_columns[1] : message['annotation']['tone'],\n",
    "                label_columns[2] : message['annotation']['content'],\n",
    "                label_columns[3] : message['annotation']['nature'],\n",
    "                label_columns[4] : message['annotation']['form2']\n",
    "            })\n",
    "\n",
    "    # Convert the entries in a dataframe\n",
    "    out_df = pd.DataFrame(flattened_data)\n",
    "    # Calculate an index for each utterance\n",
    "    out_df['utterance_num'] = out_df.groupby(['groupe_ID', 'messageID', 'role']).cumcount()\n",
    "    # Sort the columns of the dataframe\n",
    "    out_df = out_df[['seance_ID', 'groupe_ID', 'role', \n",
    "                        'messageID', 'utterance_num','message', label_columns[0],label_columns[1],label_columns[2],label_columns[3],label_columns[4]]]\n",
    "    return out_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5098eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prompts(folder: str,name:str):\n",
    "    '''\n",
    "    Reads system, user, and agent prompts from text files in a specified folder.\n",
    "\n",
    "    This function constructs file paths for `prompt_system.txt`, `prompt_user.txt`, and\n",
    "    `prompt_agent.txt` within the given folder, reads their contents, and returns them\n",
    "    as a tuple of strings.\n",
    "\n",
    "    Args:\n",
    "        folder (str): The name of the folder (relative to the parent of the current working\n",
    "                        directory under the \"coding_schemes\" directory) containing the prompt files.\n",
    "\n",
    "    Returns:\n",
    "        tuple[str, str, str]: A tuple containing three strings:\n",
    "            - PROMPT_SYSTEM: The content of `prompt_system.txt`.\n",
    "            - PROMPT_USER: The content of `prompt_user.txt`.\n",
    "            - PROMPT_AGENT: The content of `prompt_agent.txt`.\n",
    "\n",
    "    '''\n",
    "    path = Path(os.getcwd()) / folder\n",
    "    # Read the three prompts\n",
    "    PROMPT_SYSTEM_NAME = path / f\"prompt_system_{name}.txt\"\n",
    "    PROMPT_USER_NAME   = path / f\"prompt_user_from_corpus_{name}.txt\"\n",
    "    PROMPT_AGENT_NAME  = path / f\"prompt_agent_from_corpus_{name}.txt\"\n",
    "\n",
    "    \n",
    "    # Get the system, user and agent prompts as a string\n",
    "    with open(PROMPT_SYSTEM_NAME) as f:\n",
    "        PROMPT_SYSTEM= f.read()\n",
    "\n",
    "    with open(PROMPT_USER_NAME) as f:\n",
    "        PROMPT_USER = f.read()\n",
    "\n",
    "    with open(PROMPT_AGENT_NAME) as f:\n",
    "        PROMPT_AGENT = f.read()\n",
    "    # Return a tuple with the prompts\n",
    "    return (PROMPT_SYSTEM, PROMPT_USER, PROMPT_AGENT)\n",
    "\n",
    "# For error capturing\n",
    "errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60718998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentences_mistral(client: Mistral, \n",
    "                        message: str,\n",
    "                        prompt_system: str,\n",
    "                        prompt_user: str,\n",
    "                        prompt_agent: str):\n",
    "    \n",
    "    '''\n",
    "    Classifies a given message using a Mistral model with predefined prompts.\n",
    "\n",
    "    This function sends a message to the Mistral API along with system, user, and agent prompts\n",
    "    to generate a classification response. It handles errors by logging them and returning `None`\n",
    "    if the classification fails.\n",
    "\n",
    "    Args:\n",
    "        client (Mistral): An instance of the Mistral client used to interact with the API.\n",
    "        message (str): The message to be classified.\n",
    "        prompt_system (str): The system prompt to guide the model's behavior.\n",
    "        prompt_user (str): The user prompt to provide context or instructions.\n",
    "        prompt_agent (str): The agent prompt to simulate the assistant's role.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the model's response if the classification is successful.\n",
    "        None: If an error occurs during the classification process.\n",
    "    '''\n",
    "    \n",
    "    prompt = prompt_system + \"\\n Un exemple d'entrée est :\\n\" + prompt_user +\"\\n et un exemple de sortie est :\\n\"+ prompt_agent+\".\\n Les messages que tu dois annoter sont :\\n \" +message\n",
    "    #print(prompt)\n",
    "    \n",
    "\n",
    "    response = client.chat.complete(\n",
    "        model=\"open-mistral-nemo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        stream=False,\n",
    "        response_format = {\n",
    "            \"type\": \"json_object\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "    # Capture errors\n",
    "    try:\n",
    "        # If not error, we get the response\n",
    "        return response.choices[0].message.content\n",
    "    except:\n",
    "        # If error, the function returns None, but the error message is appended\n",
    "        # to a global array\n",
    "        errors.append({'message': message, 'response': response})\n",
    "        return None\n",
    "\n",
    "\n",
    "def classify_conversation_mistral(mistral_client: Mistral,\n",
    "                        prompt_system: str,\n",
    "                        prompt_user: str,\n",
    "                        prompt_agent: str,\n",
    "                        conversations: list):\n",
    "    '''\n",
    "    Classifies a list of conversations using an Mistral model with predefined prompts.\n",
    "\n",
    "    This function iterates over a list of conversations, classifies each one using the\n",
    "    `classify_sentences` function, and collects the results. A progress bar is displayed\n",
    "    to track the classification process.\n",
    "\n",
    "    Args:\n",
    "        openai_client (OpenAI): An instance of the OpenAI client used to interact with the API.\n",
    "        prompt_system (str): The system prompt to guide the model's behavior.\n",
    "        prompt_user (str): The user prompt to provide context or instructions.\n",
    "        prompt_agent (str): The agent prompt to simulate the assistant's role.\n",
    "        conversations (list): A list of conversations (strings) to be classified.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of classification results corresponding to each conversation. Each result\n",
    "                is the output of the `classify_sentences` function, which may be a string or `None`\n",
    "                if an error occurred during classification.\n",
    "    '''\n",
    "\n",
    "    out = []\n",
    "    for conversation in tqdm(conversations, desc='Classifying...'):\n",
    "        response = classify_sentences_mistral(mistral_client, \n",
    "                                        str(conversation), \n",
    "                                        prompt_system, \n",
    "                                        prompt_user, \n",
    "                                        prompt_agent)\n",
    "        out.append(response)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48251ab",
   "metadata": {},
   "source": [
    "# Recuperation des messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11ca617c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messageID</th>\n",
       "      <th>user</th>\n",
       "      <th>role</th>\n",
       "      <th>message</th>\n",
       "      <th>groupID</th>\n",
       "      <th>fileID</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>seanceID</th>\n",
       "      <th>nothing</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Contenu Jose</th>\n",
       "      <th>Contenu Chloe</th>\n",
       "      <th>Contenu Sebastien</th>\n",
       "      <th>Contenu Julien</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "      <th>Forme Jose</th>\n",
       "      <th>Forme Chloe</th>\n",
       "      <th>Forme Sebastien</th>\n",
       "      <th>Forme Julien</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>145797.0</td>\n",
       "      <td>Driver</td>\n",
       "      <td>tu pense si je fais un for in in range avec un...</td>\n",
       "      <td>4</td>\n",
       "      <td>1db9dee2-2702-457f-aa07-6b60589446ce</td>\n",
       "      <td>2024-10-09</td>\n",
       "      <td>04:25:31</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relatedToProgramming_relatedToTask</td>\n",
       "      <td>relatedToProgramming_relatedToTask</td>\n",
       "      <td>relatedToProgramming_relatedToTask</td>\n",
       "      <td>relatedToProgramming_relatedToTask</td>\n",
       "      <td>NaN</td>\n",
       "      <td>demande_validation</td>\n",
       "      <td>demande_validation</td>\n",
       "      <td>demande_conseil</td>\n",
       "      <td>demande_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>200807.0</td>\n",
       "      <td>Navigator</td>\n",
       "      <td>en vrai c'est pas mieux de faire un \"if len(a)...</td>\n",
       "      <td>4</td>\n",
       "      <td>1db9dee2-2702-457f-aa07-6b60589446ce</td>\n",
       "      <td>2024-10-09</td>\n",
       "      <td>04:28:50</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relatedToProgramming_relatedToTask</td>\n",
       "      <td>relatedToProgramming_relatedToTask</td>\n",
       "      <td>relatedToProgramming_relatedToTask</td>\n",
       "      <td>relatedToProgramming_relatedToTask</td>\n",
       "      <td>NaN</td>\n",
       "      <td>proposition_conseil</td>\n",
       "      <td>proposition_validation</td>\n",
       "      <td>proposition_validation</td>\n",
       "      <td>proposition_conseil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>200807.0</td>\n",
       "      <td>Navigator</td>\n",
       "      <td>quand je teste le code il me disent y'a des er...</td>\n",
       "      <td>4</td>\n",
       "      <td>1db9dee2-2702-457f-aa07-6b60589446ce</td>\n",
       "      <td>2024-10-09</td>\n",
       "      <td>04:30:08</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relatedToProgramming_relatedToTask</td>\n",
       "      <td>relatedToProgramming_relatedToTask</td>\n",
       "      <td>relatedToProgramming_relatedToTask</td>\n",
       "      <td>relatedToProgramming_relatedToTask</td>\n",
       "      <td>NaN</td>\n",
       "      <td>proposition_validation</td>\n",
       "      <td>proposition_validation</td>\n",
       "      <td>proposition_validation</td>\n",
       "      <td>proposition_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>182622.0</td>\n",
       "      <td>Navigator</td>\n",
       "      <td>def coincide(tableau1, tableau2):     # On s'a...</td>\n",
       "      <td>7</td>\n",
       "      <td>2855677e-e74f-4a3f-82d7-be74864de417</td>\n",
       "      <td>2024-10-09</td>\n",
       "      <td>04:30:42</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relatedToProgramming_relatedToTask</td>\n",
       "      <td>relatedToProgramming_relatedToTask</td>\n",
       "      <td>relatedToProgramming_relatedToTask</td>\n",
       "      <td>relatedToProgramming_relatedToTask</td>\n",
       "      <td>NaN</td>\n",
       "      <td>proposition_conseil</td>\n",
       "      <td>proposition_conseil</td>\n",
       "      <td>proposition_conseil</td>\n",
       "      <td>proposition_conseil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73</td>\n",
       "      <td>199277.0</td>\n",
       "      <td>Navigator</td>\n",
       "      <td>ta pas besoin du return  []</td>\n",
       "      <td>7</td>\n",
       "      <td>2855677e-e74f-4a3f-82d7-be74864de417</td>\n",
       "      <td>2024-10-09</td>\n",
       "      <td>04:37:01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relatedToProgramming_relatedToTask</td>\n",
       "      <td>relatedToProgramming_relatedToTask</td>\n",
       "      <td>relatedToProgramming_relatedToTask</td>\n",
       "      <td>relatedToProgramming_relatedToTask</td>\n",
       "      <td>NaN</td>\n",
       "      <td>proposition_conseil</td>\n",
       "      <td>proposition_conseil</td>\n",
       "      <td>proposition_validation</td>\n",
       "      <td>proposition_conseil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   messageID      user       role  \\\n",
       "0         24  145797.0     Driver   \n",
       "1         30  200807.0  Navigator   \n",
       "2         34  200807.0  Navigator   \n",
       "3         56  182622.0  Navigator   \n",
       "4         73  199277.0  Navigator   \n",
       "\n",
       "                                             message  groupID  \\\n",
       "0  tu pense si je fais un for in in range avec un...        4   \n",
       "1  en vrai c'est pas mieux de faire un \"if len(a)...        4   \n",
       "2  quand je teste le code il me disent y'a des er...        4   \n",
       "3  def coincide(tableau1, tableau2):     # On s'a...        7   \n",
       "4                        ta pas besoin du return  []        7   \n",
       "\n",
       "                                 fileID        date      time  seanceID  \\\n",
       "0  1db9dee2-2702-457f-aa07-6b60589446ce  2024-10-09  04:25:31         1   \n",
       "1  1db9dee2-2702-457f-aa07-6b60589446ce  2024-10-09  04:28:50         1   \n",
       "2  1db9dee2-2702-457f-aa07-6b60589446ce  2024-10-09  04:30:08         1   \n",
       "3  2855677e-e74f-4a3f-82d7-be74864de417  2024-10-09  04:30:42         1   \n",
       "4  2855677e-e74f-4a3f-82d7-be74864de417  2024-10-09  04:37:01         1   \n",
       "\n",
       "   nothing  ... Unnamed: 14                        Contenu Jose  \\\n",
       "0      NaN  ...         NaN  relatedToProgramming_relatedToTask   \n",
       "1      NaN  ...         NaN  relatedToProgramming_relatedToTask   \n",
       "2      NaN  ...         NaN  relatedToProgramming_relatedToTask   \n",
       "3      NaN  ...         NaN  relatedToProgramming_relatedToTask   \n",
       "4      NaN  ...         NaN  relatedToProgramming_relatedToTask   \n",
       "\n",
       "                        Contenu Chloe                   Contenu Sebastien  \\\n",
       "0  relatedToProgramming_relatedToTask  relatedToProgramming_relatedToTask   \n",
       "1  relatedToProgramming_relatedToTask  relatedToProgramming_relatedToTask   \n",
       "2  relatedToProgramming_relatedToTask  relatedToProgramming_relatedToTask   \n",
       "3  relatedToProgramming_relatedToTask  relatedToProgramming_relatedToTask   \n",
       "4  relatedToProgramming_relatedToTask  relatedToProgramming_relatedToTask   \n",
       "\n",
       "                       Contenu Julien Unnamed: 19              Forme Jose  \\\n",
       "0  relatedToProgramming_relatedToTask         NaN      demande_validation   \n",
       "1  relatedToProgramming_relatedToTask         NaN     proposition_conseil   \n",
       "2  relatedToProgramming_relatedToTask         NaN  proposition_validation   \n",
       "3  relatedToProgramming_relatedToTask         NaN     proposition_conseil   \n",
       "4  relatedToProgramming_relatedToTask         NaN     proposition_conseil   \n",
       "\n",
       "              Forme Chloe         Forme Sebastien            Forme Julien  \n",
       "0      demande_validation         demande_conseil      demande_validation  \n",
       "1  proposition_validation  proposition_validation     proposition_conseil  \n",
       "2  proposition_validation  proposition_validation  proposition_validation  \n",
       "3     proposition_conseil     proposition_conseil     proposition_conseil  \n",
       "4     proposition_conseil  proposition_validation     proposition_conseil  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"SousCorpusMessagesAgreement.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a1087da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'seance_ID': np.int64(-1),\n",
       "  'groupe_ID': np.int64(-1),\n",
       "  'conversation': [{'messageID': -1,\n",
       "    'role': '/',\n",
       "    'message': 'Tu fais un while et dedans tu incrementes'}]},\n",
       " {'seance_ID': np.int64(1),\n",
       "  'groupe_ID': np.int64(4),\n",
       "  'conversation': [{'messageID': 24,\n",
       "    'role': 'Driver',\n",
       "    'message': 'tu pense si je fais un for in in range avec un for j in range dedans �a peut marcher? '},\n",
       "   {'messageID': 30,\n",
       "    'role': 'Navigator',\n",
       "    'message': 'en vrai c\\'est pas mieux de faire un \"if len(a) != len(b)\"'},\n",
       "   {'messageID': 34,\n",
       "    'role': 'Navigator',\n",
       "    'message': \"quand je teste le code il me disent y'a des erreurs de type\"}]},\n",
       " {'seance_ID': np.int64(1),\n",
       "  'groupe_ID': np.int64(7),\n",
       "  'conversation': [{'messageID': 56,\n",
       "    'role': 'Navigator',\n",
       "    'message': 'def coincide(tableau1, tableau2):     # On s\\'assure que les deux tableaux ont la m�me longueur     if len(tableau1) != len(tableau2):         return []      # On cr�e un tableau vide pour stocker les indices o� les �l�ments sont identiques     result = []          # On parcourt les deux tableaux et on compare les �l�ments     for i in range(len(tableau1)):         if tableau1[i] == tableau2[i]:             result.append(i)      return result  # Exemples d\\'utilisation : print(coincide([78, 23, 12, 12, 54, 32], [67, 23, 44, 12, 54, 32]))  # [1, 3, 4, 5] print(coincide([\"antoine\", \"isaac\", \"denis\"], [\"jeanne\", \"sofiane\", \"lise\"]))  # []'},\n",
       "   {'messageID': 73,\n",
       "    'role': 'Navigator',\n",
       "    'message': 'ta pas besoin du return  []'},\n",
       "   {'messageID': 75, 'role': 'Navigator', 'message': \"c'est ok \"}]},\n",
       " {'seance_ID': np.int64(1),\n",
       "  'groupe_ID': np.int64(9),\n",
       "  'conversation': [{'messageID': 82,\n",
       "    'role': 'Navigator',\n",
       "    'message': 'et la ta compris un peu le contexte ? '},\n",
       "   {'messageID': 83,\n",
       "    'role': 'Driver',\n",
       "    'message': \"je sais qu''il faut impl�menter le tableau pour l'utiliser dans la fonction coincide\"}]},\n",
       " {'seance_ID': np.int64(1),\n",
       "  'groupe_ID': np.int64(16),\n",
       "  'conversation': [{'messageID': 134,\n",
       "    'role': 'Driver',\n",
       "    'message': \"j'essaye encore\"}]}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Ensure that the message num is an integer for sorting\n",
    "df['messageID'] = df['messageID'].astype(int) \n",
    "df['groupID'] = df['groupID'].astype(int) \n",
    "df['seanceID'] = df['seanceID'].astype(int)  \n",
    "\n",
    "# Group the dataframe by conversation\n",
    "grouped = df.groupby(['seanceID','groupID'])\n",
    "\n",
    "# We'll save the conversations as an array of dictionaries were every conversation is an entry\n",
    "conversations_dict = []\n",
    "# For every conversation in the dataframe\n",
    "for activity_id, group in grouped:\n",
    "    # Convert the utterances into a list of dictionaries, then sort entries by message num\n",
    "    conversation_text = group.sort_values('messageID').apply(\n",
    "        lambda row: {\"messageID\": row['messageID'], \"role\": row['role'], \"message\": row['message']},\n",
    "        axis=1\n",
    "    ).tolist()\n",
    "    \n",
    "    # Create a conversation\n",
    "    conversation = {\n",
    "        \"seance_ID\": activity_id[0],\n",
    "        \"groupe_ID\": activity_id[1],\n",
    "        \"conversation\": conversation_text\n",
    "    }\n",
    "    # Append the conversations as a dictionary\n",
    "    conversations_dict.append(conversation)\n",
    "\n",
    "# This is not a JSON, it will be important later\n",
    "conversations_dict[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c5ef6",
   "metadata": {},
   "source": [
    "# Nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c3e607a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying...: 100%|██████████| 5/5 [00:06<00:00,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "client = Mistral(api_key=api_key)\n",
    "prompt_system, prompt_user, prompt_agent = read_prompts(\"prompts_by_category\",\"nature\")\n",
    "labeled_data = classify_conversation_mistral(client,\n",
    "                                    prompt_system,\n",
    "                                    prompt_user,\n",
    "                                    prompt_agent,\n",
    "                                    conversations_dict[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3d035bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"annotations\": [{\"message_num\": -1, \"utterances\": [{\"nature\": \"Informations sur comment proceder\"}]}]}',\n",
       " '{\\n  \"annotations\": [\\n    {\\n      \"message_num\": 24,\\n      \"utterances\": [\\n        {\\n          \"nature\": \"Demande d\\'aide\"\\n        }\\n      ]\\n    },\\n    {\\n      \"message_num\": 30,\\n      \"utterances\": [\\n        {\\n          \"nature\": \"Informations sur comment proceder\"\\n        }\\n      ]\\n    },\\n    {\\n      \"message_num\": 34,\\n      \"utterances\": [\\n        {\\n          \"nature\": \"Erreurs, idees fausses\"\\n        }\\n      ]\\n    }\\n  ]\\n}',\n",
       " '{\\n  \"annotations\": [\\n    {\\n      \"message_num\": 56,\\n      \"utterances\": [\\n        {\\n          \"nature\": \"Reponse correcte\"\\n        }\\n      ]\\n    },\\n    {\\n      \"message_num\": 73,\\n      \"utterances\": [\\n        {\\n          \"nature\": \"Validite de la reponse\"\\n        }\\n      ]\\n    },\\n    {\\n      \"message_num\": 75,\\n      \"utterances\": [\\n        {\\n          \"nature\": \"Validite de la reponse\"\\n        }\\n      ]\\n    }\\n  ]\\n}',\n",
       " '{\\n  \"annotations\": [\\n    {\\n      \"message_num\": 82,\\n      \"utterances\": [\\n        {\\n          \"nature\": \"Conaissances sur les taches\"\\n        }\\n      ]\\n    },\\n    {\\n      \"message_num\": 83,\\n      \"utterances\": [\\n        {\\n          \"nature\": \"Validite de la reponse\"\\n        }\\n      ]\\n    }\\n  ]\\n}',\n",
       " '{\"annotations\": [{\"message_num\": 134, \"utterances\": [{\"nature\": \"No feedback\"}] }]}']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2db515b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'message'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m out_df = \u001b[43mconvert_to_dataframe_nature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabeled_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mconvert_to_dataframe_nature\u001b[39m\u001b[34m(list_of_json)\u001b[39m\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# For every utterance in the conversation\u001b[39;00m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m json_entry[\u001b[33m'\u001b[39m\u001b[33mannotations\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m     46\u001b[39m         \u001b[38;5;66;03m# Create an entry (row) to use then in the dataframe\u001b[39;00m\n\u001b[32m     47\u001b[39m         flattened_data.append({\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mmessage\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m     49\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mnature\u001b[39m\u001b[33m'\u001b[39m : message[\u001b[33m'\u001b[39m\u001b[33mannotation\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mnature\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     50\u001b[39m         })\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# Convert the entries in a dataframe\u001b[39;00m\n\u001b[32m     53\u001b[39m out_df = pd.DataFrame(flattened_data)\n",
      "\u001b[31mKeyError\u001b[39m: 'message'"
     ]
    }
   ],
   "source": [
    "out_df = convert_to_dataframe_nature(labeled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a082344d",
   "metadata": {},
   "source": [
    "# Contenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e6134",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Mistral(api_key=api_key)\n",
    "prompt_system, prompt_user, prompt_agent = read_prompts(\"prompts_by_category\",\"contenu\")\n",
    "labeled_data = classify_conversation_mistral(client,\n",
    "                                    prompt_system,\n",
    "                                    prompt_user,\n",
    "                                    prompt_agent,\n",
    "                                    conversations_dict[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed89986",
   "metadata": {},
   "source": [
    "# Forme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b94673",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Mistral(api_key=api_key)\n",
    "prompt_system, prompt_user, prompt_agent = read_prompts(\"prompts_by_category\",\"forme\")\n",
    "labeled_data = classify_conversation_mistral(client,\n",
    "                                    prompt_system,\n",
    "                                    prompt_user,\n",
    "                                    prompt_agent,\n",
    "                                    conversations_dict[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
